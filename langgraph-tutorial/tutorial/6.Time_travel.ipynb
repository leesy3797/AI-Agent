{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = init_chat_model('google_genai:gemini-2.0-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert_to_genai_function_declarations expects a Sequence and not a single tool.\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated \n",
    "from langchain_tavily import TavilySearch \n",
    "from langchain_core.messages import BaseMessage \n",
    "from typing_extensions import TypedDict \n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver \n",
    "from langgraph.graph import StateGraph, START, END \n",
    "from langgraph.graph.message import add_messages \n",
    "from langgraph.prebuilt import ToolNode, tools_condition \n",
    "\n",
    "class State(TypedDict):\n",
    "    messages : Annotated[list, add_messages] \n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "tool = TavilySearch(max_results = 2)\n",
    "tools = [tool] \n",
    "llm_with_tools = llm.bind_tools(tool) \n",
    "\n",
    "def chatbot(state : State):\n",
    "    return {'messages':[llm_with_tools.invoke(state['messages'])]}\n",
    "\n",
    "graph_builder.add_node('chatbot' , chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools = [tool])\n",
    "graph_builder.add_node('tools', tool_node) \n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    'chatbot',\n",
    "    tools_condition\n",
    ")\n",
    "\n",
    "graph_builder.add_edge('tools', 'chatbot')\n",
    "graph_builder.add_edge(START, 'chatbot')\n",
    "\n",
    "memory = MemorySaver() \n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph.Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (7e59211e-2e9a-43cf-b6ae-88da5a4b2fcb)\n",
      " Call ID: 7e59211e-2e9a-43cf-b6ae-88da5a4b2fcb\n",
      "  Args:\n",
      "    query: LangGraph\n",
      "    topic: general\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"LangGraph\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"title\": \"What is LangGraph? - IBM\", \"url\": \"https://www.ibm.com/think/topics/langgraph\", \"content\": \"LangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. LangGraph illuminates the processes within an AI workflow, allowing full transparency of the agent’s state. By combining these technologies with a set of APIs and tools, LangGraph provides users with a versatile platform for developing AI solutions and workflows including chatbots, state graphs and other agent-based systems. Nodes: In LangGraph, nodes represent individual components or agents within an AI workflow. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback.\", \"score\": 0.942002, \"raw_content\": null}, {\"title\": \"langchain-ai/langgraph: Build resilient language agents as graphs. - GitHub\", \"url\": \"https://github.com/langchain-ai/langgraph\", \"content\": \"GitHub - langchain-ai/langgraph: Build resilient language agents as graphs. langchain-ai.github.io/langgraph/ Trusted by companies shaping the future of agents – including Klarna, Replit, Elastic, and more – LangGraph is a low-level orchestration framework for building, managing, and deploying long-running, stateful agents. Or, to learn how to build an agent workflow with a customizable architecture, long-term memory, and other complex task handling, see the LangGraph basics tutorials. LangGraph provides low-level supporting infrastructure for _any_ long-running, stateful workflow or agent. While LangGraph can be used standalone, it also integrates seamlessly with any LangChain product, giving developers a full suite of tools for building agents. *   LangGraph Platform — Deploy and scale agents effortlessly with a purpose-built deployment platform for long running, stateful workflows. langchain-ai.github.io/langgraph/\", \"score\": 0.8987045, \"raw_content\": null}], \"response_time\": 0.8}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph, created by LangChain, is an open-source AI agent framework designed for building, deploying, and managing complex generative AI agent workflows. It utilizes graph-based architectures to model and manage the relationships between components in an AI agent workflow, providing transparency into the agent's state. It allows AI agents to analyze their past actions and feedback, enhancing decision-making by modeling complex relationships between nodes. LangGraph provides the infrastructure for long-running, stateful workflows and integrates seamlessly with LangChain products. It is trusted by companies like Klarna, Replit, and Elastic.\n"
     ]
    }
   ],
   "source": [
    "config = {'configurable' : {'thread_id' : '1'}}\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\" : [\n",
    "            {\n",
    "                \"role\" : \"user\",\n",
    "                \"content\" : (\n",
    "                    \"I'm learning LangGraph.\"\n",
    "                    \"Could you do some research on it for me?\"\n",
    "                )\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    config,\n",
    "    stream_mode = \"values\"\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Ya that's helpful. Maybe I'll build an autonomous agent with it!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds like a great project! LangGraph is designed to help with that. Is there anything else I can help you with regarding LangGraph or autonomous agents?\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"Ya that's helpful. Maybe I'll \"\n",
    "                    \"build an autonomous agent with it!\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Messages:  6 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  5 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  3 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  2 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  1 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  0 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "to_replay = None \n",
    "for state in graph.get_state_history(config):\n",
    "    print('Num Messages: ', len(state.values['messages']), \"Next: \", state.next)\n",
    "    print('-' * 80)\n",
    "    if len(state.values['messages']) == 3:\n",
    "        to_replay = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('chatbot',)\n",
      "{'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f051809-cc05-6710-8002-5da5222672a4'}}\n"
     ]
    }
   ],
   "source": [
    "print(to_replay.next)\n",
    "print(to_replay.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"LangGraph\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"title\": \"What is LangGraph? - IBM\", \"url\": \"https://www.ibm.com/think/topics/langgraph\", \"content\": \"LangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. LangGraph illuminates the processes within an AI workflow, allowing full transparency of the agent’s state. By combining these technologies with a set of APIs and tools, LangGraph provides users with a versatile platform for developing AI solutions and workflows including chatbots, state graphs and other agent-based systems. Nodes: In LangGraph, nodes represent individual components or agents within an AI workflow. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback.\", \"score\": 0.942002, \"raw_content\": null}, {\"title\": \"langchain-ai/langgraph: Build resilient language agents as graphs. - GitHub\", \"url\": \"https://github.com/langchain-ai/langgraph\", \"content\": \"GitHub - langchain-ai/langgraph: Build resilient language agents as graphs. langchain-ai.github.io/langgraph/ Trusted by companies shaping the future of agents – including Klarna, Replit, Elastic, and more – LangGraph is a low-level orchestration framework for building, managing, and deploying long-running, stateful agents. Or, to learn how to build an agent workflow with a customizable architecture, long-term memory, and other complex task handling, see the LangGraph basics tutorials. LangGraph provides low-level supporting infrastructure for _any_ long-running, stateful workflow or agent. While LangGraph can be used standalone, it also integrates seamlessly with any LangChain product, giving developers a full suite of tools for building agents. *   LangGraph Platform — Deploy and scale agents effortlessly with a purpose-built deployment platform for long running, stateful workflows. langchain-ai.github.io/langgraph/\", \"score\": 0.8987045, \"raw_content\": null}], \"response_time\": 0.8}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph, created by LangChain, is an open-source AI agent framework designed for building, deploying, and managing complex generative AI agent workflows. It uses graph-based architectures to model and manage the relationships between components in an AI agent workflow, providing transparency into the agent's state. It allows AI agents to analyze their past actions and feedback, enhancing decision-making by modeling complex relationships between nodes. LangGraph provides the infrastructure for long-running, stateful workflows or agents and integrates seamlessly with LangChain products. It is used by companies like Klarna, Replit, and Elastic.\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(\n",
    "    None, \n",
    "    to_replay.config, \n",
    "    stream_mode = 'values'\n",
    "):\n",
    "    if \"messages\" in event:\n",
    "        event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
